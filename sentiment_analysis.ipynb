{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bcpLiReEQfdW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPZXCXq1Ubxq",
        "outputId": "5bbc5085-a532-41b9-8d02-fbe68ba5c737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in d:\\anaconda\\lib\\site-packages (4.27.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in d:\\anaconda\\lib\\site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.13.2)Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers) (2022.3.15)\n",
            "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\lib\\site-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.1.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\anaconda\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
            "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-s9ZTWVPUXZD"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPwvRs8IUZWH",
        "outputId": "ad8e6e14-8cdc-45b1-d3b6-9a094e61bdb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer.vocab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y54MHIjUctm",
        "outputId": "60a4d441-286b-4718-c7c3-794f866e8a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['hello', 'world', 'how', 'are', 'you', '?']\n"
          ]
        }
      ],
      "source": [
        "tokens = tokenizer.tokenize('Hello WORLD how ARE yoU?')\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6XrvCeiUgFV",
        "outputId": "45f9f276-2b9e-4bed-99a6-bc6829976cb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7592, 2088, 2129, 2024, 2017, 1029]\n"
          ]
        }
      ],
      "source": [
        "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(indexes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19zMtepiUiXg",
        "outputId": "e9fc2f3b-00a6-4d20-d42a-7c5c7d930375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n"
          ]
        }
      ],
      "source": [
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "190HVH5oUkKe",
        "outputId": "9d24c2f9-f30a-49f4-9ee3-548c86ae3162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ]
        }
      ],
      "source": [
        "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
        "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
        "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
        "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbisTksnUmDr",
        "outputId": "dd8abf99-1bf0-4a73-e6fb-71db55b245bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ]
        }
      ],
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeX_18-JUnoR",
        "outputId": "cd000e00-8b86-422d-f931-1f6307518bfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "512\n"
          ]
        }
      ],
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
        "\n",
        "print(max_input_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "grk18A9mUpJy"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_cut(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence) \n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIr2GA0sUrQ7",
        "outputId": "94c9fd49-af23-40a9-fc71-b95ee6ae4511"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\n",
            "Requirement already satisfied: torch in d:\\anaconda\\lib\\site-packages (1.8.0)\n",
            "Requirement already satisfied: torchvision in d:\\anaconda\\lib\\site-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from torch) (1.21.5)\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torch-2.0.0%2Bcu118-cp39-cp39-win_amd64.whl (2611.4 MB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\lib\\site-packages (from torchvision) (9.0.1)"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'D:\\\\anaconda\\\\Lib\\\\site-packages\\\\~.rch\\\\lib\\\\asmjit.dll'\n",
            "Consider using the `--user` option or check the permissions.\n",
            "\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch) (3.6.0)\n",
            "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch) (2.11.3)\n",
            "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch) (1.10.1)\n",
            "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch) (2.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->torchvision) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
            "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.8.0\n",
            "    Uninstalling torch-1.8.0:\n",
            "      Successfully uninstalled torch-1.8.0\n"
          ]
        }
      ],
      "source": [
        "%pip install torch torchvision -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOnFJIojUs1I",
        "outputId": "2ea9ea5c-fd58-4c53-c4d1-e7af95b6378d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in d:\\anaconda\\lib\\site-packages (2.0.0+cu118)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "ERROR: Could not find a version that satisfies the requirement trochvision (from versions: none)\n",
            "ERROR: No matching distribution found for trochvision\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "%pip install torch trochvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiyjFjRUUvAR",
        "outputId": "4ee3a1f5-53e8-4f3e-a2be-36f401665262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.9.0 in d:\\anaconda\\lib\\site-packages (0.9.0)Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from torchtext==0.9.0) (1.21.5)\n",
            "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from torchtext==0.9.0) (4.64.0)\n",
            "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from torchtext==0.9.0) (2.27.1)\n",
            "Collecting torch==1.8.0\n",
            "  Using cached torch-1.8.0-cp39-cp39-win_amd64.whl (190.5 MB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.8.0 which is incompatible.\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\anaconda\\lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from torch==1.8.0->torchtext==0.9.0) (4.1.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\lib\\site-packages (from requests->torchtext==0.9.0) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->torchtext==0.9.0) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->torchtext==0.9.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->torchtext==0.9.0) (1.26.9)\n",
            "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm->torchtext==0.9.0) (0.4.4)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "Successfully installed torch-1.8.0\n"
          ]
        }
      ],
      "source": [
        "%pip install torchtext==0.9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "m5Llx9gAUu4H"
      },
      "outputs": [],
      "source": [
        "from torchtext.legacy import data\n",
        "\n",
        "TEXT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = tokenize_and_cut,\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "quCnGXnYUyUS"
      },
      "outputs": [],
      "source": [
        "from torchtext.legacy import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AWr_NuwSUyRe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data)}\")\n",
        "print(f\"Number of testing examples: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-nf76164UyO7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['the', 'premise', 'of', 'cabin', 'fever', 'starts', 'like', 'it', 'might', 'have', 'something', 'to', 'offer', '.', 'a', 'group', 'of', 'college', 'teens', 'after', 'finals', '(', 'in', 'the', 'fall', '?', ')', 'goes', 'to', 'a', 'resort', 'cabin', 'in', 'the', 'woods', 'where', 'one', 'by', 'one', 'they', 'are', 'attacked', 'by', 'an', 'unseen', 'flesh', 'eating', 'virus', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'unfortunately', ',', 'the', 'first', 'paragraph', 'is', 'where', 'any', 'remote', 'elements', 'of', 'film', 'quality', 'stop', '.', 'cabin', 'fever', 'is', 'little', 'more', 'than', 'college', 'kids', 'looking', 'for', 'sex', ',', 'boo', '##ze', ',', 'talking', 'non', '-', 'stop', 'about', 'nothing', ',', 'and', 'seeing', 'how', 'many', 'f', '-', 'bombs', 'they', 'can', 'get', 'into', '1', ':', '40', 'minutes', 'or', 'however', 'long', 'this', 'mess', 'is', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'kids', 'act', 'and', 'react', 'stupid', '##ly', 'to', 'everything', 'around', 'them', '.', 'one', 'of', 'them', 'for', 'instance', 'discovers', 'that', 'the', 'skin', 'virus', 'has', 'infected', 'her', 'legs', ',', 'so', 'what', 'does', 'she', 'do', '?', 'she', 'keeps', 'sha', '##ving', 'her', 'legs', 'failing', 'to', 'take', 'proper', 'medical', 'attention', 'for', 'her', 'wounds', '.', 'the', 'scene', 'is', 'little', 'more', 'than', 'a', 'gross', 'out', '.', 'in', 'another', 'scene', ',', 'rider', 'strong', 'from', '\"', 'boy', 'meets', 'world', '\"', 'gets', 'bitten', 'on', 'the', 'hand', 'by', 'some', 'kid', 'who', 'only', 'says', '\"', 'pancakes', '\"', 'and', 'likes', 'to', 'do', 'karate', 'kicks', 'on', 'those', 'who', 'sit', 'next', 'to', 'him', '.', 'if', 'you', 'can', 'figure', 'out', 'the', 'reason', 'for', 'why', 'the', '\"', 'pancakes', '\"', 'kid', 'was', 'included', ',', 'i', \"'\", 'd', 'love', 'to', 'know', '.', 'anyway', ',', 'rider', 'pets', 'a', 'wild', 'dog', 'and', 'goes', 'off', 'to', 'wash', 'his', 'bitten', 'hand', 'in', 'a', 'most', 'likely', 'contaminated', 'creek', '.', 'another', 'kid', 'likes', 'to', 'drop', 'f', '-', 'bombs', 'in', 'reacting', 'to', 'everything', 'around', 'him', 'and', 'shoot', 'squirrels', '.', 'why', '?', 'your', 'guess', 'is', 'as', 'good', 'as', 'mine', '!', '<', 'br', '/', '>', '<', 'br', '/', '>', 'rider', 'strong', 'is', 'the', 'only', 'kid', 'with', 'any', 'recognition', 'in', 'this', 'movie', '.', 'he', 'tries', 'to', 'calm', 'people', 'down', 'in', '-', 'between', 'the', 'yelling', 'and', 'screaming', 'and', 'f', '*', '*', '*', 'y', '*', '*', '!', 'bombs', 'that', 'people', 'are', 'throwing', 'around', '.', 'when', 'the', 'kids', 'aren', \"'\", 't', 'yelling', ',', 'they', 'are', 'having', 'or', 'talking', 'about', 'sex', 'or', 'talking', 'nonsense', 'to', 'the', 'other', 'adult', 'characters', 'who', 'are', 'even', 'more', '(', 'if', 'that', 'is', 'possible', ')', 'idiot', '##ic', 'than', 'the', 'kids', '!', 'the', 'idiot', 'cop', 'with', 'an', 'iq', 'of', '60', 'at', 'best', 'may', 'be', 'one', 'of', 'the', 'worst', 'acting', 'jobs', 'i', 'have', 'ever', 'seen', 'in', 'a', 'movie', '.', 'you', 'talk', 'about', 'people', 'not', 'playing', 'with', 'a', 'full', 'deck', ',', 'this', 'do', '##rk', 'doesn', \"'\", 't', 'even', 'know', 'how', 'to', 'find', 'the', 'cards', '!', 'lo', '##l', '!', 'i', 'was', 'like', ',', '\"', 'will', 'you', 'please', 'shut', 'up', 'already', '?', '!', '\"', 'he', 'makes', 'the', 'kid', 'actors', 'look', 'like', 'genius', '##es', '!', 'the', 'only', 'part', 'that', 'i', 'sort', 'of', 'liked', 'was', 'rider', \"'\", 's', 'scary', 'story', '(', 'although', 'go', '##ry', ')', 'about', 'the', 'der', '##ange', '##d', 'bowling', 'alley', 'guy', '.', 'in', 'interviews', ',', 'rider', 'said', 'that', 'he', 'had', 'a', 'great', 'deal', 'of', 'respect', 'for', 'director', 'eli', 'roth', '.']\n"
          ]
        }
      ],
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[6])['text'])\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bOJGMtyFUyMY"
      },
      "outputs": [],
      "source": [
        "LABEL.build_vocab(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U1SUoPn-UyKI"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BkZKwf3wU7CA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "### build model\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KOSN_S02U9Et"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BERTGRUSentiment(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert\n",
        "        \n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        \n",
        "        self.rnn = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [batch size, sent len]\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            embedded = self.bert(text)[0]\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        _, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #hidden = [n layers * n directions, batch size, emb dim]\n",
        "        \n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "                \n",
        "        #hidden = [batch size, hid dim]\n",
        "        \n",
        "        output = self.out(hidden)\n",
        "        \n",
        "        #output = [batch size, out dim]\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dMyDvhPuVCQr"
      },
      "outputs": [],
      "source": [
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "\n",
        "model = BERTGRUSentiment(bert,\n",
        "                         HIDDEN_DIM,\n",
        "                         OUTPUT_DIM,\n",
        "                         N_LAYERS,\n",
        "                         BIDIRECTIONAL,\n",
        "                         DROPOUT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DZSpp7ihVENb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 112,241,409 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4JSoOMwTVHit"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Pda4tvBcVMOE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 2,759,169 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ndfYb536VOKL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rnn.weight_ih_l0\n",
            "rnn.weight_hh_l0\n",
            "rnn.bias_ih_l0\n",
            "rnn.bias_hh_l0\n",
            "rnn.weight_ih_l0_reverse\n",
            "rnn.weight_hh_l0_reverse\n",
            "rnn.bias_ih_l0_reverse\n",
            "rnn.bias_hh_l0_reverse\n",
            "rnn.weight_ih_l1\n",
            "rnn.weight_hh_l1\n",
            "rnn.bias_ih_l1\n",
            "rnn.bias_hh_l1\n",
            "rnn.weight_ih_l1_reverse\n",
            "rnn.weight_hh_l1_reverse\n",
            "rnn.bias_ih_l1_reverse\n",
            "rnn.bias_hh_l1_reverse\n",
            "out.weight\n",
            "out.bias\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vQWSHouqVP4T"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2yWY5mq3VReb"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dTfFQr6oVTmY"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OCCExrzSVYSr"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "vB0i7u-dVaV-"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            print(\"epoch_acc: \", epoch_acc)\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "# def evaluate(model, iterator, criterion, device):\n",
        "#     epoch_loss = 0\n",
        "#     epoch_acc = 0\n",
        "#     model.eval()\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for batch in iterator:\n",
        "#             # Move the batch to the GPU\n",
        "#             inputs = batch.text.to(device)\n",
        "#             targets = batch.label.to(device)\n",
        "\n",
        "#             # Compute the model's output\n",
        "#             predictions = model(inputs).squeeze(1)\n",
        "\n",
        "#             # Compute the loss and accuracy\n",
        "#             loss = criterion(predictions, targets)\n",
        "#             acc = binary_accuracy(predictions, targets)\n",
        "\n",
        "#             # Update the loss and accuracy\n",
        "#             epoch_loss += loss.item()\n",
        "#             epoch_acc += acc.item()\n",
        "\n",
        "#     # Compute the average loss and accuracy\n",
        "#     num_batches = len(iterator)\n",
        "#     epoch_loss /= num_batches\n",
        "#     epoch_acc /= num_batches\n",
        "\n",
        "#     return epoch_loss, epoch_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "OmIFYuFAVcF3"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjqMmLGYVvIs"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BDR3FmtQVw0X"
      },
      "outputs": [],
      "source": [
        "# model_save_name = 'classifier.pt'\n",
        "# path = F\"C:/Users/ammar/Downloads/{model_save_name}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrBvecX0Vy8Z"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "\n",
        "# if(os.path.exists(path)):\n",
        "#     if(torch.cuda.is_available()):\n",
        "#         model.load_state_dict(torch.load(path, map_location=torch.device('cuda')))\n",
        "#         test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "#         print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
        "#     else:\n",
        "#         print(\"No GPU found\")\n",
        "#         model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
        "#         test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "#         print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
        "#         #save model for future use\n",
        "#         torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# %pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "dvZtBJZsV05_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:4000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:4000/ (Press CTRL+C to quit)\n"
          ]
        }
      ],
      "source": [
        "import flask\n",
        "from flask import Flask, request, jsonify\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    model.eval()\n",
        "    sentence = request.json['sentence']\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
        "    tensor = torch.LongTensor(indexed).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(tensor)\n",
        "    prediction = torch.sigmoid(output).item()\n",
        "    return jsonify({'sentiment_score': prediction})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=4000)\n",
        "    #print something to know it's running\n",
        "    if(app.run(port=4000)):\n",
        "        print(\"running\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfvp5RkpV90E"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.08202903717756271"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_sentiment(model, tokenizer, \"i don't like this hostel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88ISoYDuV_iF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.909687340259552"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_sentiment(model, tokenizer, \"hostel was good\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plqVYGpJWFnT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"drive/MyDrive/fast_thesis/clean_hotel_reviews.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7-tAl1fWKC3"
      },
      "outputs": [],
      "source": [
        "t_new_rate=[]\n",
        "for ind in df.index:\n",
        "  score = predict_sentiment(model, tokenizer, df['reviews.text'][ind])\n",
        "  x_std = (score - 0) / (1 - 0)\n",
        "  x_scaled = x_std * (5 - 0) + 0\n",
        "  t_new_rate.append(round(x_scaled))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
